# LLM

## inference

- [MegEngine/InferLLM](https://github.com/MegEngine/InferLLM)
- [ztxz16/fastllm](https://github.com/ztxz16/fastllm)

## serving

- [huggingface/text-generation-inference](https://github.com/huggingface/text-generation-inference)
- [ModelTC/lightllm](https://github.com/ModelTC/lightllm)


## local

- [ollama](https://github.com/ollama/ollama)
- [ktransformers](https://github.com/kvcache-ai/ktransformers)
- [lm studio](https://github.com/lmstudio-ai/lms)
- [private-gpt](https://github.com/zylon-ai/private-gpt)
- [localGPT](https://github.com/PromtEngineer/localGPT)
- [docker-llama2-chat](https://github.com/soulteary/docker-llama2-chat)

## web

- [LiLittleCat/awesome-free-chatgpt](https://github.com/LiLittleCat/awesome-free-chatgpt)
- [ramonvc/freegpt-webui](https://github.com/ramonvc/freegpt-webui)

## application builder 

- [langchain](https://github.com/langchain-ai/langchain)
- [llama_index](https://github.com/run-llama/llama_index)

## agent
